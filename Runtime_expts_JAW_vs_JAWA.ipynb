{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for empirical comparison of JAW and JAWS runtime in \"JAWS\" paper (Appendix, Table 4)\n",
    "\n",
    "These runtime experiments were run on a 2019 MacBook Pro with a 2.3 GHz 8-Core Intel Core i9 processor and 32 GB memory\n",
    "\n",
    "#### Prinster, A., Liu, A., & Saria, S. JAWS: Auditing Predictive Uncertainty Under Covariate Shift. In Advances in Neural Information Processing Systems. 2022.\n",
    "\n",
    "Last updated: January 4, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "## Dependencies from RUE\n",
    "%matplotlib inline\n",
    "\n",
    "import imp\n",
    "import logging\n",
    "imp.reload(logging)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import autograd\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import pystan\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import numpy as np \n",
    "import scipy\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from random import sample\n",
    "from utils.JAWS_utils import *\n",
    "from utils import bayesnn\n",
    "from utils.IF_utils import *\n",
    "\n",
    "# from autograd import make_jvp\n",
    "\n",
    "# import sys\n",
    "# print(sys.getrecursionlimit())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_airfoil shape :  (1503, 5)\n",
      "X_wine shape :  (1599, 11)\n",
      "X_wave shape :  (2000, 48)\n",
      "X_superconduct shape :  (2000, 81)\n",
      "X_communities shape :  (1994, 99)\n"
     ]
    }
   ],
   "source": [
    "## Load datasets\n",
    "\n",
    "airfoil = pd.read_csv('./datasets/airfoil/airfoil.txt', sep = '\\t', header=None)\n",
    "airfoil.columns = [\"Frequency\",\"Angle\",\"Chord\",\"Velocity\",\"Suction\",\"Sound\"]\n",
    "X_airfoil = airfoil.iloc[:, 0:5].values\n",
    "X_airfoil[:, 0] = np.log(X_airfoil[:, 0])\n",
    "X_airfoil[:, 4] = np.log(X_airfoil[:, 4])\n",
    "Y_airfoil = airfoil.iloc[:, 5].values\n",
    "n_airfoil = len(Y_airfoil)\n",
    "print(\"X_airfoil shape : \", X_airfoil.shape)\n",
    "        \n",
    "winequality_red = pd.read_csv('./datasets/wine/winequality-red.csv', sep=';')\n",
    "X_wine = winequality_red.iloc[:, 0:11].values\n",
    "Y_wine = winequality_red.iloc[:, 11].values\n",
    "n_wine = len(Y_wine)\n",
    "print(\"X_wine shape : \", X_wine.shape)\n",
    "        \n",
    "wave = pd.read_csv('./datasets/WECs_DataSet/Adelaide_Data.csv', header = None)\n",
    "# wave_ids = sample(range(0, len(wave)),2000)\n",
    "# X_wave = wave.iloc[wave_ids, 0:48].values\n",
    "# Y_wave = wave.iloc[wave_ids, 48].values\n",
    "X_wave = wave.iloc[0:2000, 0:48].values\n",
    "Y_wave = wave.iloc[0:2000, 48].values\n",
    "n_wave = len(Y_wave)\n",
    "print(\"X_wave shape : \", X_wave.shape)\n",
    "        \n",
    "superconduct = pd.read_csv('./datasets/superconduct/train.csv')\n",
    "# superconduct_ids = sample(range(0, len(superconduct)),2000)\n",
    "# X_superconduct = superconduct.iloc[superconduct_ids, 0:81].values\n",
    "# Y_superconduct = superconduct.iloc[superconduct_ids, 81].values\n",
    "X_superconduct = superconduct.iloc[0:2000, 0:81].values\n",
    "Y_superconduct = superconduct.iloc[0:2000, 81].values\n",
    "n_superconduct = len(Y_superconduct)\n",
    "print(\"X_superconduct shape : \", X_superconduct.shape)\n",
    "        \n",
    "# UCI Communities and Crime Data Set\n",
    "# download from:\n",
    "# http://archive.ics.uci.edu/ml/datasets/communities+and+crime\n",
    "communities_data = np.loadtxt('./datasets/communities/communities.data',delimiter=',',dtype=str)\n",
    "# remove categorical predictors\n",
    "communities_data = np.delete(communities_data,np.arange(5),1)\n",
    "# remove predictors with missing values\n",
    "communities_data = np.delete(communities_data,\\\n",
    "            np.argwhere((communities_data=='?').sum(0)>0).reshape(-1),1)\n",
    "communities_data = communities_data.astype(float)\n",
    "X_communities = communities_data[:,:-1]\n",
    "Y_communities = communities_data[:,-1]\n",
    "n_communities = len(Y_communities)\n",
    "print(\"X_communities shape : \", X_communities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## Select dataset\n",
    "    # dataset = 'airfoil'\n",
    "\n",
    "def load_dataset(dataset):\n",
    "        n = 200\n",
    "        train_inds = np.random.choice(eval('n_'+dataset),n,replace=False)\n",
    "        # train_inds = list(range(0, n))\n",
    "        test_inds = np.setdiff1d(np.arange(eval('n_'+dataset)),train_inds)\n",
    "\n",
    "#         print(\"train_inds[0:10] : \", train_inds[0:10])\n",
    "#         print(\"test_inds[0:10] : \", test_inds[0:10])\n",
    "\n",
    "        X = eval('X_'+dataset)[train_inds]\n",
    "        Y = eval('Y_'+dataset)[train_inds]\n",
    "        X1 = eval('X_'+dataset)[test_inds]\n",
    "        Y1 = eval('Y_'+dataset)[test_inds]\n",
    "\n",
    "        ## Normalize data\n",
    "        norm_X = InputNormalizer(X)\n",
    "        norm_y = TargetNormalizer(Y)\n",
    "\n",
    "        X = norm_X.normalize(X)\n",
    "        Y = norm_y.normalize(Y)\n",
    "\n",
    "        X1 = norm_X.normalize(X1)\n",
    "        Y1 = norm_y.normalize(Y1)\n",
    "\n",
    "        return X, Y, X1, Y1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example empirical runtime for JAW (Prinster et al., 2022) or Jackknife+ (Barber et al., 2021) with leave-one-out retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomState(MT19937)\n",
      "\n",
      "Time beginning :  2022-07-21 03:33:02.385043\n",
      "train_inds[0:10] :  [ 640   75  154 1247 1025   32  604  968  624  227]\n",
      "test_inds[0:10] :  [ 0  1  2  3  4  5  7  8  9 10]\n",
      "\n",
      " DATASET :  airfoil\n",
      "\n",
      "Beginning retraining for airfoil:  2022-07-21 03:33:02.387628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [58:39<00:00, 17.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ending retraining for airfoil:  2022-07-21 04:31:42.263123\n",
      "train_inds[0:10] :  [  29 1202 1008  328  808  220  770  776  250 1325]\n",
      "test_inds[0:10] :  [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      " DATASET :  wine\n",
      "\n",
      "Beginning retraining for wine:  2022-07-21 04:31:42.266604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [57:35<00:00, 17.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ending retraining for wine:  2022-07-21 05:29:17.982011\n",
      "train_inds[0:10] :  [ 682 1579 1195 1825  901  259 1617  232 1679  470]\n",
      "test_inds[0:10] :  [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      " DATASET :  wave\n",
      "\n",
      "Beginning retraining for wave:  2022-07-21 05:29:17.986075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 200/200 [1:11:54<00:00, 21.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ending retraining for wave:  2022-07-21 06:41:12.267468\n",
      "train_inds[0:10] :  [ 384  844  764 1266  920 1444   26 1194  263  344]\n",
      "test_inds[0:10] :  [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      " DATASET :  superconduct\n",
      "\n",
      "Beginning retraining for superconduct:  2022-07-21 06:41:12.272935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 200/200 [1:17:15<00:00, 23.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ending retraining for superconduct:  2022-07-21 07:58:27.386353\n",
      "train_inds[0:10] :  [1440  561 1231 1194 1421  664  217 1900 1120 1837]\n",
      "test_inds[0:10] :  [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      " DATASET :  communities\n",
      "\n",
      "Beginning retraining for communities:  2022-07-21 07:58:27.393949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 200/200 [1:20:42<00:00, 24.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ending retraining for communities:  2022-07-21 09:19:09.535821\n",
      "\n",
      "Time of completion :  2022-07-21 09:19:09.535976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Trying now with Hessian having 10.0 as dampening\n",
    "print(np.random.RandomState(12345))\n",
    "ntrial = 1\n",
    "alpha = 0.1\n",
    "damp = 0.0 ## default dampening\n",
    "method_names = ['IF1-jackknife', 'IF1-jackknife-mm', 'IF1-jackknife+', 'IF1-JAWA', \n",
    "                'IF2-jackknife', 'IF2-jackknife-mm', 'IF2-jackknife+', 'IF2-JAWA',\n",
    "                'IF3-jackknife', 'IF3-jackknife-mm', 'IF3-jackknife+', 'IF3-JAWA']\n",
    "\n",
    "print(\"\\nTime beginning : \", datetime.now())\n",
    "\n",
    "for dataset in ['airfoil', 'wine', 'wave', 'superconduct', 'communities']: #'airfoil', 'wave', , 'communities'\n",
    "    \n",
    "    X2_train, y2_train, X2_test, y2_test = load_dataset(dataset)\n",
    "    \n",
    "    print(\"\\n DATASET : \", dataset)\n",
    "\n",
    "    if (dataset == 'airfoil'):\n",
    "        bias = 0.85\n",
    "        L2_lambda = 1\n",
    "    elif (dataset == 'wine'):\n",
    "        bias = 0.53\n",
    "        L2_lambda = 8\n",
    "    elif (dataset == 'wave'):\n",
    "        bias = 0.0000925\n",
    "        L2_lambda = 4\n",
    "    elif (dataset in ['superconduct']):\n",
    "        bias = 0.00062\n",
    "        L2_lambda = 96\n",
    "    elif (dataset == 'communities'):\n",
    "        bias = 0.825\n",
    "        L2_lambda = 64\n",
    "        \n",
    "    rng = np.random.RandomState(0) ## Generate random state with seed=0\n",
    "\n",
    "    n_train, n_inputs = X2_train.shape\n",
    "    n_hidden = 25\n",
    "\n",
    "    alphas = [1.0, 1.0]\n",
    "    beta = 1.0\n",
    "    \n",
    "    print(\"\\nBeginning retraining for \" + str(dataset) + \": \", datetime.now())\n",
    "    for i in tqdm.tqdm(range(0, n_train)):\n",
    "\n",
    "\n",
    "\n",
    "        ############# Full model\n",
    "\n",
    "        model = bayesnn.MLP(n_inputs, n_hidden)\n",
    "        init_params = model.init_params(rng)\n",
    "\n",
    "        weights = np.ones(n_train)\n",
    "        weights[i] = 0\n",
    "\n",
    "        objective, likelihood, prior, likelihood_all = bayesnn.make_objective(model, alphas, beta, n_train, weights)\n",
    "\n",
    "        config = bayesnn.init_sgd_config()\n",
    "        config['n_epochs'] = 2000\n",
    "        config['batch_size'] = 50\n",
    "\n",
    "        params = bayesnn.train(objective, init_params, X2_train, y2_train, config, weights)\n",
    "        y_hat_full = model.predict(params, X2_test)\n",
    "    \n",
    "    print(\"\\nEnding retraining for \" + str(dataset) + \": \", datetime.now())\n",
    "    \n",
    "\n",
    "\n",
    "print(\"\\nTime of completion : \", datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example empirical runtime for JAWA (influence function Approximation of JAW to avoid retraining)\n",
    "Default below is 3rd order IF approximation. See Note towards bottom of cell below on how to change between 1st, 2nd, or 3rd order IF approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomState(MT19937)\n",
      "\n",
      "Time beginning :  2023-01-04 23:24:21.624671\n",
      "\n",
      " DATASET :  airfoil\n",
      "\n",
      "Beginning IFs for airfoil:  2023-01-04 23:24:37.444226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:12<00:00, 15.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ending IFs for airfoil:  2023-01-04 23:24:50.353394\n",
      "\n",
      " DATASET :  wine\n",
      "\n",
      "Beginning IFs for wine:  2023-01-04 23:25:06.963235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:13<00:00, 14.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ending IFs for wine:  2023-01-04 23:25:21.121288\n",
      "\n",
      " DATASET :  wave\n",
      "\n",
      "Beginning IFs for wave:  2023-01-04 23:25:42.073963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:18<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ending IFs for wave:  2023-01-04 23:26:02.686127\n",
      "\n",
      " DATASET :  superconduct\n",
      "\n",
      "Beginning IFs for superconduct:  2023-01-04 23:26:26.054970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:27<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ending IFs for superconduct:  2023-01-04 23:26:57.406084\n",
      "\n",
      " DATASET :  communities\n",
      "\n",
      "Beginning IFs for communities:  2023-01-04 23:27:22.023549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:35<00:00,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ending IFs for communities:  2023-01-04 23:28:01.963919\n",
      "\n",
      "Time of completion :  2023-01-04 23:28:01.964090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Trying now with Hessian having 10.0 as dampening\n",
    "print(np.random.RandomState(12345))\n",
    "ntrial = 1\n",
    "alpha = 0.1\n",
    "damp = 0.0 ## default dampening\n",
    "method_names = ['IF1-jackknife', 'IF1-jackknife-mm', 'IF1-jackknife+', 'IF1-JAWA', \n",
    "                'IF2-jackknife', 'IF2-jackknife-mm', 'IF2-jackknife+', 'IF2-JAWA',\n",
    "                'IF3-jackknife', 'IF3-jackknife-mm', 'IF3-jackknife+', 'IF3-JAWA']\n",
    "\n",
    "print(\"\\nTime beginning : \", datetime.now())\n",
    "\n",
    "for dataset in ['airfoil', 'wine', 'wave', 'superconduct', 'communities']: #'airfoil', 'wave', , 'communities'\n",
    "    \n",
    "    X2_train, y2_train, X2_test, y2_test = load_dataset(dataset)\n",
    "    \n",
    "    print(\"\\n DATASET : \", dataset)\n",
    "\n",
    "    if (dataset == 'airfoil'):\n",
    "        bias = 0.85\n",
    "        L2_lambda = 1\n",
    "    elif (dataset == 'wine'):\n",
    "        bias = 0.53\n",
    "        L2_lambda = 8\n",
    "    elif (dataset == 'wave'):\n",
    "        bias = 0.0000925\n",
    "        L2_lambda = 4\n",
    "    elif (dataset in ['superconduct']):\n",
    "        bias = 0.00062\n",
    "        L2_lambda = 96\n",
    "    elif (dataset == 'communities'):\n",
    "        bias = 0.825\n",
    "        L2_lambda = 64\n",
    "        \n",
    "    rng = np.random.RandomState(0) ## Generate random state with seed=0\n",
    "\n",
    "    n_train, n_inputs = X2_train.shape\n",
    "    n_hidden = 25\n",
    "\n",
    "    alphas = [1.0, 1.0]\n",
    "    beta = 1.0\n",
    "    \n",
    "    \n",
    "    rng = np.random.RandomState(0) ## Generate random state with seed=0\n",
    "\n",
    "    n_train, n_inputs = X2_train.shape\n",
    "    n_hidden = 25\n",
    "\n",
    "    alphas = [1.0, 1.0]\n",
    "    beta = 1.0\n",
    "\n",
    "    ############# Full model\n",
    "\n",
    "    model = bayesnn.MLP(n_inputs, n_hidden)\n",
    "    init_params = model.init_params(rng)\n",
    "\n",
    "    weights = np.ones(n_train)\n",
    "\n",
    "    objective, likelihood, prior, likelihood_all = bayesnn.make_objective(model, alphas, beta, n_train, weights)\n",
    "\n",
    "    config = bayesnn.init_sgd_config()\n",
    "    config['n_epochs'] = 2000\n",
    "    config['batch_size'] = 50\n",
    "\n",
    "    params = bayesnn.train(objective, init_params, X2_train, y2_train, config, weights)\n",
    "    y_hat_full = model.predict(params, X2_test)\n",
    "\n",
    "    print(\"\\nBeginning IFs for \" + str(dataset) + \": \", datetime.now())\n",
    "\n",
    "    ## Hessian\n",
    "    damp = 0.0\n",
    "    H = autograd.hessian(likelihood_all, 0)(params, X2_train, y2_train, weights)\n",
    "    H = H + damp * np.eye(len(H))\n",
    "    H_inv = np.linalg.inv(H)\n",
    "\n",
    "\n",
    "    for i in tqdm.tqdm(range(0, n_train)):\n",
    "        weights = np.ones(n_train)\n",
    "        weights[i] = 0\n",
    "\n",
    "        ############ IF approximations\n",
    "        ''' NOTE:\n",
    "            -\n",
    "        '''\n",
    "\n",
    "        ## 1st-order IF\n",
    "        params_IFs_1 = EvaluateThetaIJ(1, params, H_inv, likelihood_all, X2_train, y2_train, weights)\n",
    "        y_hat_IFs_1 = model.predict(params_IFs_1, X2_test)\n",
    "\n",
    "        ## 2nd-order IF\n",
    "        params_IFs_2 = EvaluateThetaIJ(2, params, H_inv, likelihood_all, X2_train, y2_train, weights)\n",
    "        y_hat_IFs_2 = model.predict(params_IFs_2, X2_test)\n",
    "\n",
    "        ## 3rd-order IF\n",
    "        params_IFs_3 = EvaluateThetaIJ(3, params, H_inv, likelihood_all, X2_train, y2_train, weights)\n",
    "        y_hat_IFs_3 = model.predict(params_IFs_3, X2_test)\n",
    "\n",
    "    \n",
    "    print(\"\\nEnding IFs for \" + str(dataset) + \": \", datetime.now())\n",
    "\n",
    "\n",
    "print(\"\\nTime of completion : \", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
